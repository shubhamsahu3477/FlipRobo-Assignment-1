{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping - Assignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#!pip install bs4\n",
    "#!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's import the required libraries\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 :- Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Header Tag H1</th>\n",
       "      <th>Header Tag H2</th>\n",
       "      <th>Header Tag H3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "      <td>From today's featured article</td>\n",
       "      <td>Languages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>Did you know ...</td>\n",
       "      <td>Personal tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>In the news</td>\n",
       "      <td>Namespaces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>On this day</td>\n",
       "      <td>Variants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>Today's featured picture</td>\n",
       "      <td>Views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "      <td>More</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "      <td>Navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>Wikipedia languages</td>\n",
       "      <td>Contribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>Navigation menu</td>\n",
       "      <td>Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Print/export</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>In other projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Header Tag H1                  Header Tag H2      Header Tag H3\n",
       "0      Main Page  From today's featured article          Languages\n",
       "1           None               Did you know ...     Personal tools\n",
       "2           None                    In the news         Namespaces\n",
       "3           None                    On this day           Variants\n",
       "4           None       Today's featured picture              Views\n",
       "5           None       Other areas of Wikipedia               More\n",
       "6           None    Wikipedia's sister projects         Navigation\n",
       "7           None            Wikipedia languages         Contribute\n",
       "8           None                Navigation menu              Tools\n",
       "9           None                           None       Print/export\n",
       "10          None                           None  In other projects\n",
       "11          None                           None          Languages"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "wikipage_content=requests.get(\n",
    "     'https://en.wikipedia.org/wiki/Main_Page'\n",
    ")\n",
    "\n",
    "header = html.fromstring(wikipage_content.content)\n",
    "\n",
    "scrape = ['h1','h2','h3']\n",
    "tag1 = []\n",
    "tag2 = []\n",
    "tag3 = []\n",
    "\n",
    "while True:\n",
    "    for element in scrape:\n",
    "        path = f'//{element}'\n",
    "        for j in range(len(header.xpath(path))):\n",
    "            if element == 'h1':\n",
    "                tag1.append(header.xpath(path)[j].text_content())\n",
    "            elif element == 'h2':\n",
    "                tag2.append(header.xpath(path)[j].text_content())\n",
    "            else:\n",
    "                custom_path = path + '/span'\n",
    "                tag3.append(header.xpath(custom_path)[j-1].text_content())  # this step is customized for getting the h3 tag content accurately\n",
    "    break\n",
    "\n",
    "dict = {'Header Tag H1':tag1,'Header Tag H2':tag2,'Header Tag H3':tag3}\n",
    "wiki_header = pd.DataFrame.from_dict(dict, orient='index').T\n",
    "wiki_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2 - Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_movies(url):\n",
    "    Names=[]\n",
    "    Ratings=[]\n",
    "    Years=[]\n",
    "    imdb_page=requests.get(url)\n",
    "    imdb_soup=BeautifulSoup(imdb_page.content,'html.parser')\n",
    "    imdb_name=imdb_soup.find_all('td',class_=\"titleColumn\")\n",
    "    for i in imdb_name:\n",
    "        full_name=i.find('a').get_text()\n",
    "        Names.append(full_name)\n",
    "    imdb_rating=imdb_soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "    for i in imdb_rating:\n",
    "        Ratings.append(i.text.replace('\\n',''))\n",
    "    imdb_year=imdb_soup.find_all('span',class_=\"secondaryInfo\")\n",
    "    for i in imdb_year:\n",
    "        Years.append(i.text.replace('(','').replace(')',''))\n",
    "    import pandas as pd\n",
    "    movies=pd.DataFrame({})\n",
    "    movies['Names']=Names\n",
    "    movies['Ratings']=Ratings\n",
    "    movies['Years']=Years\n",
    "    movies=movies[:100]\n",
    "    print(movies)\n",
    "    movies.to_csv('Top_100_imdb_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Names Ratings Years\n",
      "0   The Shawshank Redemption     9.2  1994\n",
      "1              The Godfather     9.1  1972\n",
      "2     The Godfather: Part II     9.0  1974\n",
      "3            The Dark Knight     9.0  2008\n",
      "4               12 Angry Men     8.9  1957\n",
      "..                       ...     ...   ...\n",
      "95              Citizen Kane     8.3  1941\n",
      "96                    Dangal     8.3  2016\n",
      "97         Full Metal Jacket     8.2  1987\n",
      "98       Ladri di biciclette     8.2  1948\n",
      "99       Singin' in the Rain     8.2  1952\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "imdb_movies_list=imdb_movies('https://www.imdb.com/chart/top/')\n",
    "imdb_movies_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3 - Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imdb_in(url):\n",
    "    Names=[]\n",
    "    Ratings=[]\n",
    "    Years=[]\n",
    "    imdb_in_page=requests.get(url)\n",
    "    imdb_in_soup=BeautifulSoup(imdb_in_page.content,'html.parser')\n",
    "    imdb_in_name=imdb_in_soup.find_all('td',class_=\"titleColumn\")\n",
    "    for i in imdb_in_name:\n",
    "        full_name=i.find('a').get_text()\n",
    "        Names.append(full_name)\n",
    "    imdb_in_rating=imdb_in_soup.find_all('td',class_=\"ratingColumn imdbRating\")\n",
    "    for i in imdb_in_rating:\n",
    "        Ratings.append(i.text.replace('\\n',''))\n",
    "    imdb_in_year=imdb_in_soup.find_all('span',class_=\"secondaryInfo\")\n",
    "    for i in imdb_in_year:\n",
    "        Years.append(i.text.replace('(','').replace(')',''))\n",
    "    import pandas as pd\n",
    "    movies=pd.DataFrame({})\n",
    "    movies['Names']=Names\n",
    "    movies['Ratings']=Ratings\n",
    "    movies['Years']=Years\n",
    "    movies=movies[:100]\n",
    "    print(movies)\n",
    "    movies.to_csv('Top_100_Indian_imdb_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Names Ratings Years\n",
      "0   Pather Panchali     8.5  1955\n",
      "1          Gol Maal     8.5  1979\n",
      "2          Ratsasan     8.5  2018\n",
      "3        Anbe Sivam     8.5  2003\n",
      "4           Nayakan     8.5  1987\n",
      "..              ...     ...   ...\n",
      "95            Lucia     8.0  2013\n",
      "96           Bombay     8.0  1995\n",
      "97          Maqbool     8.0  2003\n",
      "98           Omkara     8.0  2006\n",
      "99      Section 375     8.0  2019\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "imdb_india_movies=imdb_in('https://www.imdb.com/india/top-rated-indian-movies/')\n",
    "imdb_india_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 - Write a python program to scrap book name, author name, genre and book review of any 5 books from ‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book(url):\n",
    "    book_names=[]\n",
    "    author_names=[]\n",
    "    genres=[]\n",
    "    reviews=[]\n",
    "    book_page=requests.get(url)\n",
    "    book_soup=BeautifulSoup(book_page.content,'html.parser')\n",
    "    bookpage=book_soup.find_all('h4',class_='italic')\n",
    "    for i in bookpage:\n",
    "        book_names.append(i.find('a').text)\n",
    "    book_author=book_soup.find_all('p',class_='sans bold')\n",
    "    for i in book_author:\n",
    "        author_names.append(i.text.replace('\\n',''))\n",
    "    book_genre=book_soup.find_all('p',class_='genre-links hidden-phone')\n",
    "    for i in book_genre:\n",
    "        genres.append(i.find('a').text)\n",
    "    book_review=book_soup.find_all('p',class_='excerpt')\n",
    "    for i in book_review:\n",
    "        reviews.append(i.text.replace('\\n',''))\n",
    "    import pandas as pd\n",
    "    books=pd.DataFrame({})\n",
    "    books['Book Name']=book_names\n",
    "    books['Author Name']=author_names\n",
    "    books['Book Genres']=genres\n",
    "    books['Book Reviews']=reviews\n",
    "    books=books.head()\n",
    "    return(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Book Genres</th>\n",
       "      <th>Book Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>★ The Midnight Fair</td>\n",
       "      <td>Gideon Sterer, Mariachiara Di Giorgio</td>\n",
       "      <td>Children's</td>\n",
       "      <td>While some books light paths with their words,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>★ City of the Uncommon Thief</td>\n",
       "      <td>Lynne Bertrand</td>\n",
       "      <td>YA</td>\n",
       "      <td>When you see “Relevant Maps” listed as the fir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How the One-Armed Sister Sweeps Her House</td>\n",
       "      <td>Cherie Jones</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>In her engrossing and darkly lyrical debut nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Super Host</td>\n",
       "      <td>Kate Russo</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>In Super Host, the first novel from Kate Russo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Paris Library</td>\n",
       "      <td>Janet Skeslien Charles</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>One might wonder if anything new can be writte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Book Name  \\\n",
       "0                        ★ The Midnight Fair   \n",
       "1               ★ City of the Uncommon Thief   \n",
       "2  How the One-Armed Sister Sweeps Her House   \n",
       "3                                 Super Host   \n",
       "4                          The Paris Library   \n",
       "\n",
       "                             Author Name Book Genres  \\\n",
       "0  Gideon Sterer, Mariachiara Di Giorgio  Children's   \n",
       "1                         Lynne Bertrand          YA   \n",
       "2                           Cherie Jones     Fiction   \n",
       "3                             Kate Russo     Fiction   \n",
       "4                 Janet Skeslien Charles     Fiction   \n",
       "\n",
       "                                        Book Reviews  \n",
       "0  While some books light paths with their words,...  \n",
       "1  When you see “Relevant Maps” listed as the fir...  \n",
       "2  In her engrossing and darkly lyrical debut nov...  \n",
       "3  In Super Host, the first novel from Kate Russo...  \n",
       "4  One might wonder if anything new can be writte...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Book_Page=book('https://bookpage.com/reviews')\n",
    "Book_Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5 - Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_teams(url):\n",
    "    teams=[]\n",
    "    matches=[]\n",
    "    points=[]\n",
    "    ratings=[]\n",
    "    odi_team_page=requests.get(url)\n",
    "    odi_team_soup=BeautifulSoup(odi_team_page.content,'html.parser')\n",
    "    \n",
    "    odi_team=odi_team_soup.find_all('span',class_='u-hide-phablet')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text)\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    # We can observe from the inspect that in the table top row style is different and other rows are different from each other\n",
    "    # We we are going to take the top and other row seprately\n",
    "    \n",
    "    match_row1=odi_team_soup.find_all('td',class_='rankings-block__banner--matches')\n",
    "    \n",
    "    for i in match_row1:\n",
    "        matches.append(i.text)\n",
    "\n",
    "               \n",
    "    # For other rows\n",
    "    match_row2=odi_team_soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in range(0,len(match_row2),2):\n",
    "        matches.append(match_row2[i].text)\n",
    "    matches=matches[:10]\n",
    "    \n",
    "    \n",
    "    # For point also top and other rows have differnt format\n",
    "    odi_point1=odi_team_soup.find_all('td',class_='rankings-block__banner--points')\n",
    "    \n",
    "    for i in odi_point1:\n",
    "        points.append(i.text)\n",
    "        \n",
    "    \n",
    "    odi_point2=odi_team_soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in range(1,len(match_row2),2):\n",
    "        points.append(odi_point2[i].text)\n",
    "    points=points[:10]\n",
    "    \n",
    "    \n",
    "    odi_rating=odi_team_soup.find_all('td',class_='rankings-block__banner--rating u-text-right')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text.replace('\\n','').replace(' ',''))\n",
    "    \n",
    "    odi_rating=odi_team_soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text.replace('\\n','').replace(' ',''))\n",
    "    ratings=ratings[:10]\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    teams_odi=pd.DataFrame({})\n",
    "    teams_odi['teams']=teams\n",
    "    teams_odi['matches']=matches\n",
    "    teams_odi['points']=points\n",
    "    teams_odi['ratings']=ratings\n",
    "    return(teams_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teams</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>England</td>\n",
       "      <td>44</td>\n",
       "      <td>5,405</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>52</td>\n",
       "      <td>6,102</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>32</td>\n",
       "      <td>3,716</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>39</td>\n",
       "      <td>4,344</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>31</td>\n",
       "      <td>3,345</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>35</td>\n",
       "      <td>3,490</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>37</td>\n",
       "      <td>3,366</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>39</td>\n",
       "      <td>3,297</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>46</td>\n",
       "      <td>3,402</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>31</td>\n",
       "      <td>1,844</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          teams matches points ratings\n",
       "0       England      44  5,405     123\n",
       "1         India      52  6,102     117\n",
       "2   New Zealand      32  3,716     116\n",
       "3     Australia      39  4,344     111\n",
       "4  South Africa      31  3,345     108\n",
       "5      Pakistan      35  3,490     100\n",
       "6    Bangladesh      37  3,366      91\n",
       "7     Sri Lanka      39  3,297      85\n",
       "8   West Indies      46  3,402      74\n",
       "9   Afghanistan      31  1,844      59"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI_team_men=odi_teams('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')\n",
    "ODI_team_men"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_batsmen(url):\n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    batsmen_page=requests.get(url)\n",
    "    batsmen_soup=BeautifulSoup(batsmen_page.content,'html.parser')\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_player=batsmen_soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in odi_player:\n",
    "        players.append(i.text)\n",
    "    \n",
    "    # Other rows in the table\n",
    "    odi_player=batsmen_soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in odi_player:\n",
    "        players.append(i.find('a').text)\n",
    "    players=players[:10]\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_team=batsmen_soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "    #  Other rows in the table\n",
    "    odi_team=batsmen_soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_rating=batsmen_soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "    #  Other rows in the table\n",
    "    odi_rating=batsmen_soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "    ratings=ratings[:10]\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    batsmen_odi=pd.DataFrame({})\n",
    "    batsmen_odi['players']=players\n",
    "    batsmen_odi['teams']=teams\n",
    "    batsmen_odi['ratings']=ratings\n",
    "    return(batsmen_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               players teams ratings\n",
       "0          Virat Kohli   IND     870\n",
       "1         Rohit Sharma   IND     842\n",
       "2           Babar Azam   PAK     837\n",
       "3          Ross Taylor    NZ     818\n",
       "4          Aaron Finch   AUS     791\n",
       "5  Francois du Plessis    SA     790\n",
       "6         David Warner   AUS     773\n",
       "7      Kane Williamson    NZ     765\n",
       "8      Quinton de Kock    SA     755\n",
       "9       Jonny Bairstow   ENG     754"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_batsmen=odi_batsmen('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')\n",
    "top_odi_batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_bowler(url):\n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    bowler_page=requests.get(url)\n",
    "    bowler_soup=BeautifulSoup(bowler_page.content,'html.parser')\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_player=bowler_soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in odi_player:\n",
    "        players.append(i.text)\n",
    "    \n",
    "    # Other rows in the table\n",
    "    odi_player=bowler_soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in odi_player:\n",
    "        players.append(i.find('a').text)\n",
    "    players=players[:10]\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_team=bowler_soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "    #  Other rows in the table\n",
    "    odi_team=bowler_soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_rating=bowler_soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "    #  Other rows in the table\n",
    "    odi_rating=bowler_soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "    ratings=ratings[:10]\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    bowler_odi=pd.DataFrame({})\n",
    "    bowler_odi['players']=players\n",
    "    bowler_odi['teams']=teams\n",
    "    bowler_odi['ratings']=ratings\n",
    "    return(bowler_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mohammad Amir</td>\n",
       "      <td>PAK</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             players teams ratings\n",
       "0        Trent Boult    NZ     722\n",
       "1   Mujeeb Ur Rahman   AFG     708\n",
       "2     Jasprit Bumrah   IND     700\n",
       "3       Mehedi Hasan   BAN     694\n",
       "4       Chris Woakes   ENG     675\n",
       "5      Kagiso Rabada    SA     665\n",
       "6     Josh Hazlewood   AUS     660\n",
       "7  Mustafizur Rahman   BAN     658\n",
       "8      Mohammad Amir   PAK     647\n",
       "9        Pat Cummins   AUS     646"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_odi_bowler=odi_bowler('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')\n",
    "top_odi_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questin 6 - Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_women_team(url):\n",
    "    teams=[]\n",
    "    matches=[]\n",
    "    points=[]\n",
    "    ratings=[]\n",
    "    odi_team_page=requests.get(url)\n",
    "    odi_team_soup=BeautifulSoup(odi_team_page.content,'html.parser')\n",
    "    \n",
    "    odi_team=odi_team_soup.find_all('span',class_='u-hide-phablet')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text)\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    # We can observe from the inspect that in the table top row style is different and other rows are different from each other\n",
    "    # We we are going to take the top and other row seprately\n",
    "    \n",
    "    match_row1=odi_team_soup.find_all('td',class_='rankings-block__banner--matches')\n",
    "    \n",
    "    for i in match_row1:\n",
    "        matches.append(i.text)\n",
    "\n",
    "               \n",
    "    # For other rows\n",
    "    match_row2=odi_team_soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in range(0,len(match_row2),2):\n",
    "        matches.append(match_row2[i].text)\n",
    "    matches=matches[:10]\n",
    "    \n",
    "    \n",
    "    # For point also top and other rows have differnt format\n",
    "    odi_point1=odi_team_soup.find_all('td',class_='rankings-block__banner--points')\n",
    "    \n",
    "    for i in odi_point1:\n",
    "        points.append(i.text)\n",
    "        \n",
    "    \n",
    "    odi_point2=odi_team_soup.find_all('td',class_='table-body__cell u-center-text')\n",
    "    for i in range(1,len(match_row2),2):\n",
    "        points.append(odi_point2[i].text)\n",
    "    points=points[:10]\n",
    "    \n",
    "    \n",
    "    odi_rating=odi_team_soup.find_all('td',class_='rankings-block__banner--rating u-text-right')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text.replace('\\n','').replace(' ',''))\n",
    "    \n",
    "    odi_rating=odi_team_soup.find_all('td',class_='table-body__cell u-text-right rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text.replace('\\n','').replace(' ',''))\n",
    "    ratings=ratings[:10]\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    teams_odi=pd.DataFrame({})\n",
    "    teams_odi['teams']=teams\n",
    "    teams_odi['matches']=matches\n",
    "    teams_odi['points']=points\n",
    "    teams_odi['ratings']=ratings\n",
    "    return(teams_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>teams</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>15</td>\n",
       "      <td>2,436</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>15</td>\n",
       "      <td>1,812</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>England</td>\n",
       "      <td>14</td>\n",
       "      <td>1,670</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>19</td>\n",
       "      <td>2,090</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>15</td>\n",
       "      <td>1,384</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          teams matches points ratings\n",
       "0     Australia      15  2,436     162\n",
       "1         India      15  1,812     121\n",
       "2       England      14  1,670     119\n",
       "3  South Africa      19  2,090     110\n",
       "4   New Zealand      15  1,384      92\n",
       "5   West Indies      12  1,025      85\n",
       "6      Pakistan      15  1,101      73\n",
       "7    Bangladesh       5    306      61\n",
       "8     Sri Lanka      11    519      47\n",
       "9       Ireland       2     25      13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ODI_team_women=odi_women_team('https://www.icc-cricket.com/rankings/womens/team-rankings/odi')\n",
    "ODI_team_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 women’s ODI players along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_women(url):\n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    batsmen_page=requests.get(url)\n",
    "    batsmen_soup=BeautifulSoup(batsmen_page.content,'html.parser')\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_player=batsmen_soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in odi_player:\n",
    "        players.append(i.text)\n",
    "    \n",
    "    # Other rows in the table\n",
    "    odi_player=batsmen_soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in odi_player:\n",
    "        players.append(i.find('a').text)\n",
    "    players=players[:10]\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_team=batsmen_soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "    #  Other rows in the table\n",
    "    odi_team=batsmen_soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_rating=batsmen_soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "    #  Other rows in the table\n",
    "    odi_rating=batsmen_soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "    ratings=ratings[:10]\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    batsmen_odi=pd.DataFrame({})\n",
    "    batsmen_odi['players']=players\n",
    "    batsmen_odi['teams']=teams\n",
    "    batsmen_odi['ratings']=ratings\n",
    "    return(batsmen_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             players teams ratings\n",
       "0        Meg Lanning   AUS     749\n",
       "1    Stafanie Taylor    WI     746\n",
       "2       Alyssa Healy   AUS     741\n",
       "3    Smriti Mandhana   IND     732\n",
       "4  Amy Satterthwaite    NZ     723\n",
       "5     Tammy Beaumont   ENG     716\n",
       "6    Laura Wolvaardt    SA     691\n",
       "7       Ellyse Perry   AUS     691\n",
       "8        Mithali Raj   IND     687\n",
       "9        Lizelle Lee    SA     681"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_odi_batsmen=odi_women('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')\n",
    "top10_odi_batsmen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def odi_women_allrounder(url):\n",
    "    players=[]\n",
    "    teams=[]\n",
    "    ratings=[]\n",
    "    bowler_page=requests.get(url)\n",
    "    bowler_soup=BeautifulSoup(bowler_page.content,'html.parser')\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_player=bowler_soup.find_all('div',class_='rankings-block__banner--name-large')\n",
    "    for i in odi_player:\n",
    "        players.append(i.text)\n",
    "    \n",
    "    # Other rows in the table\n",
    "    odi_player=bowler_soup.find_all('td',class_='table-body__cell rankings-table__name name')\n",
    "    for i in odi_player:\n",
    "        players.append(i.find('a').text)\n",
    "    players=players[:10]\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_team=bowler_soup.find_all('div',class_='rankings-block__banner--nationality')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "        \n",
    "    #  Other rows in the table\n",
    "    odi_team=bowler_soup.find_all('span',class_='table-body__logo-text')\n",
    "    for i in odi_team:\n",
    "        teams.append(i.text.replace('\\n',''))\n",
    "    teams=teams[:10]\n",
    "    \n",
    "    # First Row of the table\n",
    "    odi_rating=bowler_soup.find_all('div',class_='rankings-block__banner--rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "        \n",
    "    #  Other rows in the table\n",
    "    odi_rating=bowler_soup.find_all('td',class_='table-body__cell rating')\n",
    "    for i in odi_rating:\n",
    "        ratings.append(i.text)\n",
    "    ratings=ratings[:10]\n",
    "    \n",
    "    \n",
    "    import pandas as pd\n",
    "    bowler_odi=pd.DataFrame({})\n",
    "    bowler_odi['players']=players\n",
    "    bowler_odi['teams']=teams\n",
    "    bowler_odi['ratings']=ratings\n",
    "    return(bowler_odi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>players</th>\n",
       "      <th>teams</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Shikha Pandey</td>\n",
       "      <td>IND</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            players teams ratings\n",
       "0      Ellyse Perry   AUS     460\n",
       "1   Stafanie Taylor    WI     410\n",
       "2    Marizanne Kapp    SA     396\n",
       "3     Deepti Sharma   IND     359\n",
       "4     Jess Jonassen   AUS     301\n",
       "5  Dane van Niekerk    SA     297\n",
       "6     Sophie Devine    NZ     289\n",
       "7    Natalie Sciver   ENG     273\n",
       "8     Shikha Pandey   IND     250\n",
       "9   Katherine Brunt   ENG     232"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top10_odi_bowler=odi_women_allrounder('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')\n",
    "top10_odi_bowler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 - Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_page=requests.get('https://www.amazon.in/best-mobile-under-20000/s?k=best+mobile+under+20000')\n",
    "amazon_soup= BeautifulSoup(amazon_page.content,'html.parser')\n",
    "\n",
    "Product=[] \n",
    "Price=[]\n",
    "Rating=[]\n",
    "Image=[]\n",
    "\n",
    "item= amazon_soup.find_all('span',class_='a-size-medium a-color-base a-text-normal')\n",
    "for i in item:\n",
    "    Product.append(i.text)\n",
    "price= amazon_soup.find_all('span',class_='a-price-whole')\n",
    "for i in price:\n",
    "    Price.append(i.text)\n",
    "rating= amazon_soup.find_all('span',class_='a-icon-alt')\n",
    "for i in rating:\n",
    "    Rating.append(i.text)\n",
    "image= amazon_soup.find_all('div', class_='a-section aok-relative s-image-fixed-height')\n",
    "for i in image:\n",
    "    Image.append(i.find('img'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 5 6 5\n"
     ]
    }
   ],
   "source": [
    "print(len('Product'),len('Price'),len('Rating'),len('Image'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product</th>\n",
       "      <th>Price</th>\n",
       "      <th>Image</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)</td>\n",
       "      <td>8,999</td>\n",
       "      <td>[\\n]</td>\n",
       "      <td>4 Stars &amp; Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Redmi 9A (Nature Green, 2GB Ram, 32GB Storage)</td>\n",
       "      <td>6,999</td>\n",
       "      <td>[]</td>\n",
       "      <td>3 Stars &amp; Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>11,990</td>\n",
       "      <td>[]</td>\n",
       "      <td>2 Stars &amp; Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Samsung Galaxy M01 Core (Black, 2GB RAM, 32GB ...</td>\n",
       "      <td>19,499</td>\n",
       "      <td>[]</td>\n",
       "      <td>1 Star &amp; Up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Samsung Galaxy M01 (Blue, 3GB RAM, 32GB Storag...</td>\n",
       "      <td>13,999</td>\n",
       "      <td>[]</td>\n",
       "      <td>4.0 out of 5 stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Product   Price Image  \\\n",
       "0          Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)   8,999  [\\n]   \n",
       "1     Redmi 9A (Nature Green, 2GB Ram, 32GB Storage)   6,999    []   \n",
       "2  Oppo A31 (Fantasy White, 6GB RAM, 128GB Storag...  11,990    []   \n",
       "3  Samsung Galaxy M01 Core (Black, 2GB RAM, 32GB ...  19,499    []   \n",
       "4  Samsung Galaxy M01 (Blue, 3GB RAM, 32GB Storag...  13,999    []   \n",
       "\n",
       "               Rating  \n",
       "0        4 Stars & Up  \n",
       "1        3 Stars & Up  \n",
       "2        2 Stars & Up  \n",
       "3         1 Star & Up  \n",
       "4  4.0 out of 5 stars  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Product=Product[0:5]\n",
    "Price=Price[0:5]\n",
    "Rating=Rating[0:5]\n",
    "image=image[0:5]\n",
    "\n",
    "import pandas as pd\n",
    "Mobiles=pd.DataFrame({})\n",
    "Mobiles['Product']=Product\n",
    "Mobiles['Price']=Price\n",
    "Mobiles['Image']=Image[0:5]\n",
    "Mobiles['Rating']=Rating\n",
    "Mobiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8 - Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Short Desription</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Today</td>\n",
       "      <td>Today Sunny</td>\n",
       "      <td>64</td>\n",
       "      <td>Sunny, with a high near 64. Calm wind becoming...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>Tonight Partly cloudy</td>\n",
       "      <td>44</td>\n",
       "      <td>Partly cloudy, with a low around 44. West wind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunday Mostly sunny</td>\n",
       "      <td>62</td>\n",
       "      <td>Mostly sunny, with a high near 62. West wind 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>Sunday Night Patchy fog after 3am.  Otherwise</td>\n",
       "      <td>34</td>\n",
       "      <td>Night Patchy fog after 3am.  Otherwise, mostly...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Monday Patchy fog before 7am.  Otherwise</td>\n",
       "      <td>75</td>\n",
       "      <td>Patchy fog before 7am.  Otherwise, mostly clou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Monday Night Mostly cloudy</td>\n",
       "      <td>47</td>\n",
       "      <td>Night Mostly cloudy, with a low around 47.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Tuesday Patchy fog between 7am and 8am.  Other...</td>\n",
       "      <td>78</td>\n",
       "      <td>Patchy fog between 7am and 8am.  Otherwise, mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Tuesday Night Mostly cloudy</td>\n",
       "      <td>48</td>\n",
       "      <td>Night Mostly cloudy, with a low around 48.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Wednesday Mostly sunny</td>\n",
       "      <td>60</td>\n",
       "      <td>Mostly sunny, with a high near 60.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Wednesday Night Partly cloudy</td>\n",
       "      <td>46</td>\n",
       "      <td>Night Partly cloudy, with a low around 46.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ThursdayA</td>\n",
       "      <td>ThursdayA slight  chance of rain.  Partly sunny</td>\n",
       "      <td>59</td>\n",
       "      <td>slight  chance of rain.  Partly sunny, with a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Thursday Night A chance of rain.  Mostly cloudy</td>\n",
       "      <td>47</td>\n",
       "      <td>Night A chance of rain.  Mostly cloudy, with a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Friday A chance of rain.  Partly sunny</td>\n",
       "      <td>59</td>\n",
       "      <td>A chance of rain.  Partly sunny, with a high n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Period                                   Short Desription  Temperature  \\\n",
       "0       Today                                        Today Sunny           64   \n",
       "1     Tonight                              Tonight Partly cloudy           44   \n",
       "2      Sunday                                Sunday Mostly sunny           62   \n",
       "3      Sunday      Sunday Night Patchy fog after 3am.  Otherwise           34   \n",
       "4      Monday           Monday Patchy fog before 7am.  Otherwise           75   \n",
       "5      Monday                         Monday Night Mostly cloudy           47   \n",
       "6     Tuesday  Tuesday Patchy fog between 7am and 8am.  Other...           78   \n",
       "7     Tuesday                        Tuesday Night Mostly cloudy           48   \n",
       "8   Wednesday                             Wednesday Mostly sunny           60   \n",
       "9   Wednesday                      Wednesday Night Partly cloudy           46   \n",
       "10  ThursdayA    ThursdayA slight  chance of rain.  Partly sunny           59   \n",
       "11   Thursday    Thursday Night A chance of rain.  Mostly cloudy           47   \n",
       "12     Friday             Friday A chance of rain.  Partly sunny           59   \n",
       "\n",
       "                                          Description  \n",
       "0   Sunny, with a high near 64. Calm wind becoming...  \n",
       "1   Partly cloudy, with a low around 44. West wind...  \n",
       "2   Mostly sunny, with a high near 62. West wind 3...  \n",
       "3   Night Patchy fog after 3am.  Otherwise, mostly...  \n",
       "4   Patchy fog before 7am.  Otherwise, mostly clou...  \n",
       "5          Night Mostly cloudy, with a low around 47.  \n",
       "6   Patchy fog between 7am and 8am.  Otherwise, mo...  \n",
       "7          Night Mostly cloudy, with a low around 48.  \n",
       "8                  Mostly sunny, with a high near 60.  \n",
       "9          Night Partly cloudy, with a low around 46.  \n",
       "10  slight  chance of rain.  Partly sunny, with a ...  \n",
       "11  Night A chance of rain.  Mostly cloudy, with a...  \n",
       "12  A chance of rain.  Partly sunny, with a high n...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from lxml import html\n",
    "import re\n",
    "\n",
    "pageContent=requests.get(\n",
    "     'https://forecast.weather.gov/MapClick.php?lat=37.77493000000004&lon=-122.41941999999995#.X7vZI1UzbIU'\n",
    ")\n",
    "\n",
    "sf = html.fromstring(pageContent.content)\n",
    "\n",
    "period = []\n",
    "short_desription = []\n",
    "temprature = []\n",
    "description = []\n",
    "\n",
    "for t in sf.xpath(\"//div[contains(@class,'row-forecast')]\"):\n",
    "    \n",
    "    if 'ight' in t.text_content():\n",
    "        temp = t.text_content().replace('ight','ight ')\n",
    "        period.append(temp.split()[0])\n",
    "        short_desription.append(temp.split(',')[0])\n",
    "        temprature.append(int(''.join(re.findall('[0-9]',temp))[:2]))\n",
    "        description.append(''.join(temp.split(' ',maxsplit=1)[1:]))\n",
    "        \n",
    "    else:\n",
    "        temp = t.text_content().replace('day','day ')\n",
    "        period.append(temp.split()[0])\n",
    "        short_desription.append(temp.split(',')[0])\n",
    "        temprature.append(int(''.join(re.findall('[0-9]',temp))[:2]))\n",
    "        description.append(''.join(temp.split(' ',maxsplit=1)[1:]))\n",
    "        \n",
    "sf_weather = pd.DataFrame({'Period':period,'Short Desription':short_desription,'Temperature':temprature,'Description':description})\n",
    "sf_weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9 -Write a python program to scrape ‘software developer’ job listings from ‘Monster.com’. It should include all the jobs listed for the next 5 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monster_job(url):\n",
    "    job_page=requests.get(url)\n",
    "    job_soup=BeautifulSoup(job_page.content,'html.parser')\n",
    "    \n",
    "    jobs=[]\n",
    "    job=job_soup.find_all('h2',class_='title')\n",
    "    for i in job:\n",
    "        jobs.append(i.text.replace('\\r\\n',''))\n",
    "    \n",
    "    Days=[]\n",
    "    day=job_soup.find_all('div',class_='meta flex-col')\n",
    "    for i in day:\n",
    "        Days.append(i.text.replace('\\n','').replace('Applied\\n\\n\\n\\nSaved\\n\\n',''))\n",
    "    \n",
    "    Company=[]\n",
    "    comp=job_soup.find_all('span',class_='name')\n",
    "    # Even Indices are companies\n",
    "    for i in range(0,len(comp),2):\n",
    "        Company.append(comp[i].text)\n",
    "        \n",
    "    Location=[]\n",
    "    # Odd Indices are companies\n",
    "    for i in range(1,len(comp),2):\n",
    "        Location.append(comp[i].text.replace('\\r\\n',''))\n",
    "        \n",
    "    import pandas as pd\n",
    "    monster_job=pd.DataFrame({})\n",
    "    monster_job['Job Name']=jobs\n",
    "    monster_job['Posted']=Days\n",
    "    monster_job['Company Name']=Company\n",
    "    monster_job['Location']=Location\n",
    "    return(monster_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Name</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead CDISC Programmer (ADaM)</td>\n",
       "      <td>3 days agoAppliedSaved</td>\n",
       "      <td>The Emmes Company, LLC</td>\n",
       "      <td>Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinical SAS Programmer</td>\n",
       "      <td>5 days agoAppliedSaved</td>\n",
       "      <td>The Emmes Company, LLC</td>\n",
       "      <td>Bangalore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Software Developer</td>\n",
       "      <td>16 days agoAppliedSaved</td>\n",
       "      <td>Aurigo</td>\n",
       "      <td>Bangalore, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Software Engineer (L2), UI/Frontend Developer</td>\n",
       "      <td>16 days agoAppliedSaved</td>\n",
       "      <td>Twilio</td>\n",
       "      <td>Bengaluru, Karnataka, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sr. Ruby on Rails Developer</td>\n",
       "      <td>3 days agoAppliedSaved</td>\n",
       "      <td>Matchpoint Solutions</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Software Engineer - Backend (GoLang/Jav...</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>EagleView Technologies</td>\n",
       "      <td>Bengaluru, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Engineer - .Net Core &amp; Vue JS - Banga...</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>MRI Software</td>\n",
       "      <td>Bangalore, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Full Stack Developer (m/f/d)</td>\n",
       "      <td>26 days agoAppliedSaved</td>\n",
       "      <td>Delivery Hero</td>\n",
       "      <td>Panjim, Goa, India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tableau Developer</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>Diverse Lynx India</td>\n",
       "      <td>Hyderabad/Gandhinagar/Chennai/Bangalore/Mumbai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Software Engineer (.Net Developer)</td>\n",
       "      <td>16 days agoAppliedSaved</td>\n",
       "      <td>Aurigo</td>\n",
       "      <td>Bangalore, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Software Engineer (L3), Developer Experience</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>Twilio</td>\n",
       "      <td>Bengaluru, Karnataka, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Senior Software Engineer - .Net core &amp; Vue JS ...</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>MRI Software</td>\n",
       "      <td>Bangalore, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Software Engineer II - Backend (GoLang) - Beng...</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>EagleView Technologies</td>\n",
       "      <td>Bengaluru, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Power BI developer - Remote India</td>\n",
       "      <td>29 days agoAppliedSaved</td>\n",
       "      <td>Matchpoint Solutions</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Software Engineer (Mobile App Development)</td>\n",
       "      <td>16 days agoAppliedSaved</td>\n",
       "      <td>Aurigo</td>\n",
       "      <td>Bangalore, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Staff Software Engineer (L4)</td>\n",
       "      <td>25 days agoAppliedSaved</td>\n",
       "      <td>Twilio</td>\n",
       "      <td>Bengaluru, Karnataka, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Software Engineer (.Net) - Bangalore, Karnataka</td>\n",
       "      <td>2 days agoAppliedSaved</td>\n",
       "      <td>MRI Software</td>\n",
       "      <td>Bangalore, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Software Engineer I - C#.net - Bengaluru, Karn...</td>\n",
       "      <td>5 days agoAppliedSaved</td>\n",
       "      <td>EagleView Technologies</td>\n",
       "      <td>Bengaluru, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Software Engineer - Big Data -P3</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>Twilio</td>\n",
       "      <td>Bengaluru, Karnataka, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Cloud Operations Engineer</td>\n",
       "      <td>1 day agoAppliedSaved</td>\n",
       "      <td>Aurigo</td>\n",
       "      <td>Bengaluru, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Software Engineer - .Net - Bangalore, Karnataka</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>MRI Software</td>\n",
       "      <td>Bangalore, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Senior Software Engineer - C#.net - Bengaluru,...</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>EagleView Technologies</td>\n",
       "      <td>Bengaluru, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Staff Software Engineer (L4)</td>\n",
       "      <td>1 day agoAppliedSaved</td>\n",
       "      <td>Twilio</td>\n",
       "      <td>Bengaluru, Karnataka, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Senior Software Engineer - (Angular) - Bangalo...</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>MRI Software</td>\n",
       "      <td>Bangalore, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Senior Software Engineer -  Backend (GoLang/Ja...</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>EagleView Technologies</td>\n",
       "      <td>Bengaluru, KT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Job Name  \\\n",
       "0                        Lead CDISC Programmer (ADaM)   \n",
       "1                             Clinical SAS Programmer   \n",
       "2                           Senior Software Developer   \n",
       "3       Software Engineer (L2), UI/Frontend Developer   \n",
       "4                         Sr. Ruby on Rails Developer   \n",
       "5   Senior Software Engineer - Backend (GoLang/Jav...   \n",
       "6   Software Engineer - .Net Core & Vue JS - Banga...   \n",
       "7                        Full Stack Developer (m/f/d)   \n",
       "8                                   Tableau Developer   \n",
       "9                  Software Engineer (.Net Developer)   \n",
       "10       Software Engineer (L3), Developer Experience   \n",
       "11  Senior Software Engineer - .Net core & Vue JS ...   \n",
       "12  Software Engineer II - Backend (GoLang) - Beng...   \n",
       "13                  Power BI developer - Remote India   \n",
       "14         Software Engineer (Mobile App Development)   \n",
       "15                       Staff Software Engineer (L4)   \n",
       "16    Software Engineer (.Net) - Bangalore, Karnataka   \n",
       "17  Software Engineer I - C#.net - Bengaluru, Karn...   \n",
       "18                   Software Engineer - Big Data -P3   \n",
       "19                          Cloud Operations Engineer   \n",
       "20    Software Engineer - .Net - Bangalore, Karnataka   \n",
       "21  Senior Software Engineer - C#.net - Bengaluru,...   \n",
       "22                       Staff Software Engineer (L4)   \n",
       "23  Senior Software Engineer - (Angular) - Bangalo...   \n",
       "24  Senior Software Engineer -  Backend (GoLang/Ja...   \n",
       "\n",
       "                      Posted            Company Name  \\\n",
       "0     3 days agoAppliedSaved  The Emmes Company, LLC   \n",
       "1     5 days agoAppliedSaved  The Emmes Company, LLC   \n",
       "2    16 days agoAppliedSaved                  Aurigo   \n",
       "3    16 days agoAppliedSaved                  Twilio   \n",
       "4     3 days agoAppliedSaved    Matchpoint Solutions   \n",
       "5   +30 days agoAppliedSaved  EagleView Technologies   \n",
       "6   +30 days agoAppliedSaved            MRI Software   \n",
       "7    26 days agoAppliedSaved           Delivery Hero   \n",
       "8   +30 days agoAppliedSaved      Diverse Lynx India   \n",
       "9    16 days agoAppliedSaved                  Aurigo   \n",
       "10  +30 days agoAppliedSaved                  Twilio   \n",
       "11  +30 days agoAppliedSaved            MRI Software   \n",
       "12  +30 days agoAppliedSaved  EagleView Technologies   \n",
       "13   29 days agoAppliedSaved    Matchpoint Solutions   \n",
       "14   16 days agoAppliedSaved                  Aurigo   \n",
       "15   25 days agoAppliedSaved                  Twilio   \n",
       "16    2 days agoAppliedSaved            MRI Software   \n",
       "17    5 days agoAppliedSaved  EagleView Technologies   \n",
       "18  +30 days agoAppliedSaved                  Twilio   \n",
       "19     1 day agoAppliedSaved                  Aurigo   \n",
       "20  +30 days agoAppliedSaved            MRI Software   \n",
       "21  +30 days agoAppliedSaved  EagleView Technologies   \n",
       "22     1 day agoAppliedSaved                  Twilio   \n",
       "23  +30 days agoAppliedSaved            MRI Software   \n",
       "24  +30 days agoAppliedSaved  EagleView Technologies   \n",
       "\n",
       "                                          Location  \n",
       "0                                        Bangalore  \n",
       "1                                        Bangalore  \n",
       "2                                    Bangalore, KT  \n",
       "3                         Bengaluru, Karnataka, KT  \n",
       "4                                           Remote  \n",
       "5                                    Bengaluru, KT  \n",
       "6                                    Bangalore, KT  \n",
       "7                               Panjim, Goa, India  \n",
       "8   Hyderabad/Gandhinagar/Chennai/Bangalore/Mumbai  \n",
       "9                                    Bangalore, KT  \n",
       "10                        Bengaluru, Karnataka, KT  \n",
       "11                                   Bangalore, KT  \n",
       "12                                   Bengaluru, KT  \n",
       "13                                          Remote  \n",
       "14                                   Bangalore, KT  \n",
       "15                        Bengaluru, Karnataka, KT  \n",
       "16                                   Bangalore, KT  \n",
       "17                                   Bengaluru, KT  \n",
       "18                        Bengaluru, Karnataka, KT  \n",
       "19                                   Bengaluru, KT  \n",
       "20                                   Bangalore, KT  \n",
       "21                                   Bengaluru, KT  \n",
       "22                        Bengaluru, Karnataka, KT  \n",
       "23                                   Bangalore, KT  \n",
       "24                                   Bengaluru, KT  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_monster=monster_job('https://www.monster.com/jobs/search/?q=Software-Developer&where=india')\n",
    "job_monster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10 -Write a python program to scrape ‘data scientist’ job listings for location ‘New Delhi’ from ‘Monster.com’. It should include all the jobs listed for the next 5 pages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monster_job(url):\n",
    "    job_page=requests.get(url)\n",
    "    job_soup=BeautifulSoup(job_page.content,'html.parser')\n",
    "    \n",
    "    jobs=[]\n",
    "    job=job_soup.find_all('h2',class_='title')\n",
    "    for i in job:\n",
    "        jobs.append(i.text.replace('\\r\\n',''))\n",
    "    \n",
    "    Days=[]\n",
    "    day=job_soup.find_all('div',class_='meta flex-col')\n",
    "    for i in day:\n",
    "        Days.append(i.text.replace('\\n','').replace('Applied\\n\\n\\n\\nSaved\\n\\n',''))\n",
    "    \n",
    "    Company=[]\n",
    "    comp=job_soup.find_all('span',class_='name')\n",
    "    # Even Indices are companies\n",
    "    for i in range(0,len(comp),2):\n",
    "        Company.append(comp[i].text)\n",
    "        \n",
    "    Location=[]\n",
    "    # Odd Indices are companies\n",
    "    for i in range(1,len(comp),2):\n",
    "        Location.append(comp[i].text.replace('\\r\\n',''))\n",
    "        \n",
    "    import pandas as pd\n",
    "    monster_job=pd.DataFrame({})\n",
    "    monster_job['Job Name']=jobs\n",
    "    monster_job['Posted']=Days\n",
    "    monster_job['Company Name']=Company\n",
    "    monster_job['Location']=Location\n",
    "    return(monster_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Name</th>\n",
       "      <th>Posted</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Scientist - Bengaluru, Karnataka</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>EagleView Technologies</td>\n",
       "      <td>Bengaluru, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist - Bengaluru, Karnataka</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>EagleView Technologies</td>\n",
       "      <td>Bengaluru, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Science Quality Assessment Engineer - Ben...</td>\n",
       "      <td>25 days agoAppliedSaved</td>\n",
       "      <td>EagleView Technologies</td>\n",
       "      <td>Bengaluru, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Senior Manager , Software Engineering (L5)</td>\n",
       "      <td>15 days agoAppliedSaved</td>\n",
       "      <td>Twilio</td>\n",
       "      <td>Bengaluru, Karnataka, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Software Engineer (UI Development)</td>\n",
       "      <td>16 days agoAppliedSaved</td>\n",
       "      <td>Aurigo</td>\n",
       "      <td>Bangalore, KT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IT JOBS HYDERABAD,TELANAGANA,INDIA</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>GENUINE IT JOBS HYDERABAD</td>\n",
       "      <td>HYDERABAD,TELANGANA,INDIA, AS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Engineering Manager, Machine Learning</td>\n",
       "      <td>+30 days agoAppliedSaved</td>\n",
       "      <td>Twilio</td>\n",
       "      <td>Bengaluru, Karnataka, KT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job Name  \\\n",
       "0         Lead Data Scientist - Bengaluru, Karnataka   \n",
       "1       Senior Data Scientist - Bengaluru, Karnataka   \n",
       "2  Data Science Quality Assessment Engineer - Ben...   \n",
       "3         Senior Manager , Software Engineering (L5)   \n",
       "4          Senior Software Engineer (UI Development)   \n",
       "5                 IT JOBS HYDERABAD,TELANAGANA,INDIA   \n",
       "6       Senior Engineering Manager, Machine Learning   \n",
       "\n",
       "                     Posted               Company Name  \\\n",
       "0  +30 days agoAppliedSaved     EagleView Technologies   \n",
       "1  +30 days agoAppliedSaved     EagleView Technologies   \n",
       "2   25 days agoAppliedSaved     EagleView Technologies   \n",
       "3   15 days agoAppliedSaved                     Twilio   \n",
       "4   16 days agoAppliedSaved                     Aurigo   \n",
       "5  +30 days agoAppliedSaved  GENUINE IT JOBS HYDERABAD   \n",
       "6  +30 days agoAppliedSaved                     Twilio   \n",
       "\n",
       "                        Location  \n",
       "0                  Bengaluru, KT  \n",
       "1                  Bengaluru, KT  \n",
       "2                  Bengaluru, KT  \n",
       "3       Bengaluru, Karnataka, KT  \n",
       "4                  Bangalore, KT  \n",
       "5  HYDERABAD,TELANGANA,INDIA, AS  \n",
       "6       Bengaluru, Karnataka, KT  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataScientist=monster_job('https://www.monster.com/jobs/search/?q=data-science&where=india')\n",
    "DataScientist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
